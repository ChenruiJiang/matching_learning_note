# match-learning

[toc]  
机器学习笔记

[GItHub使用指南](https://blog.csdn.net/Hanani_Jia/article/details/77950594)  
[GitHub 编辑指导](https://blog.csdn.net/ljc_563812704/article/details/53464039)  
[GItHub 公式编辑](https://www.jianshu.com/p/fd97e1f8f699)  
[Markdown 教程](https://hacpai.com/guide/markdown)  

## 计算机视觉面试问题  

### [SVM](https://blog.csdn.net/v_july_v/article/details/7624837)  

### [CNN](https://blog.csdn.net/fengbingchun/article/details/50529500)  

### [softmax函数](https://blog.csdn.net/u014380165/article/details/77284921)  

### [attention](https://blog.csdn.net/guohao_zhang/article/details/79540014)  

### data augmentation  

### 正则化  

### 网络参数是如何计算的  

### [ShuffleNet](https://blog.csdn.net/u011974639/article/details/79200559)  

### [我对ShuffleNet的理解](https://github.com/holyhond/Interview-question-collection/blob/master/shuffleNet.md)  

### [deepwise separable conv](https://yinguobing.com/separable-convolution/#fn2)  

### [最优化方法](http://www.cnblogs.com/maybe2030/p/4751804.html#_label0)  

1.[数学概念](https://blog.csdn.net/majinlei121/article/details/47260917)  

### [RNN](https://blog.csdn.net/heyongluoyao8/article/details/48636251)  

### [LSTM](https://blog.csdn.net/gzj_1101/article/details/79376798)  

### [RPN](https://blog.csdn.net/sloanqin/article/details/51545125)  

### PCA  

### K_means  

### KNN  

### [损失函数](https://blog.csdn.net/kangyi411/article/details/78969642)  

### 梯度消失和梯度弥散  

### SITF  

### Dropout  

### Pooling  

### Batch Normalization  

### L1正则化和L2正则化  

## 数据结构和算法问题  

### [线性代数](https://www.cnblogs.com/guoyaohua/p/9803027.html)  

### [堆和栈的区别](https://blog.csdn.net/hairetz/article/details/4141043)  

### [LeetCode刷题总结](https://github.com/holyhond/Interview-question-collection/blob/master/LeetCode.md)  

## [计算机视觉及深度学习岗位应聘问题](https://blog.csdn.net/ferriswym/article/details/81331191)  
